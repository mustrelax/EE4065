{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1c9fba75",
            "metadata": {},
            "source": [
                "# YOLO-FastestV2 Digit Detection\n",
                "\n",
                "Train a lightweight YOLO-style detector for handwritten digit recognition on ESP32-CAM.\n",
                "\n",
                "**Model**: YoloFastestV2 (adapted from https://github.com/dog-qiuqiu/Yolo-FastestV2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7696a6d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "PROJECT_ROOT = \"/content/drive/My Drive/EE4065_Project\"\n",
                "DATASET_PATH = os.path.join(PROJECT_ROOT, \"dataset\")\n",
                "OUTPUT_PATH = os.path.join(PROJECT_ROOT, \"output\")\n",
                "\n",
                "os.makedirs(DATASET_PATH, exist_ok=True)\n",
                "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
                "\n",
                "print(f\"Dataset: {DATASET_PATH}\")\n",
                "print(f\"Output: {OUTPUT_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3221d4a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "\n",
                "import sys\n",
                "sys.path.append(os.getcwd())\n",
                "\n",
                "from dataset import SyntheticDigitDataset, RESOLUTION, CELLS, CATEGORIES\n",
                "from model import YoloFastestV2, DetectionLoss\n",
                "\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "BATCH = 16\n",
                "EPOCHS = 15\n",
                "LR = 0.001"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5bd26386",
            "metadata": {},
            "source": [
                "## Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "58fa33bb",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = SyntheticDigitDataset(train_mode=True, root_folder=DATASET_PATH)\n",
                "loader = DataLoader(train_data, batch_size=BATCH, shuffle=True, num_workers=2)\n",
                "\n",
                "sample_imgs, _ = next(iter(loader))\n",
                "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
                "for i, ax in enumerate(axes):\n",
                "    ax.imshow(sample_imgs[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
                "    ax.axis('off')\n",
                "plt.suptitle('Training Samples')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd2506e2",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9bc8f30f",
            "metadata": {},
            "outputs": [],
            "source": [
                "net = YoloFastestV2().to(DEVICE)\n",
                "opt = optim.Adam(net.parameters(), lr=LR)\n",
                "loss_fn = DetectionLoss()\n",
                "\n",
                "history = []\n",
                "\n",
                "for ep in range(EPOCHS):\n",
                "    net.train()\n",
                "    ep_loss = 0\n",
                "    \n",
                "    for imgs, truth in loader:\n",
                "        imgs, truth = imgs.to(DEVICE), truth.to(DEVICE)\n",
                "        \n",
                "        opt.zero_grad()\n",
                "        out = net(imgs)\n",
                "        loss = loss_fn(out, truth)\n",
                "        loss.backward()\n",
                "        opt.step()\n",
                "        \n",
                "        ep_loss += loss.item()\n",
                "        \n",
                "    avg = ep_loss / len(loader)\n",
                "    history.append(avg)\n",
                "    print(f\"[{ep+1}/{EPOCHS}] Loss: {avg:.4f}\")\n",
                "\n",
                "print(\"Done.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d6c6c242",
            "metadata": {},
            "source": [
                "## Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2cf99dee",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8, 4))\n",
                "plt.plot(range(1, EPOCHS+1), history, 'b-o')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training Progress')\n",
                "plt.grid(True)\n",
                "plt.savefig(os.path.join(OUTPUT_PATH, 'training_curve.png'))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3908c968",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_predictions(model, dataloader):\n",
                "    pred_list, true_list = [], []\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        for imgs, truth in dataloader:\n",
                "            out = model(imgs.to(DEVICE)).cpu().numpy()\n",
                "            truth = truth.numpy()\n",
                "            \n",
                "            mask = truth[..., 0] == 1\n",
                "            if mask.sum() > 0:\n",
                "                pred_cat = np.argmax(out[mask][:, 5:], axis=1)\n",
                "                true_cat = np.argmax(truth[mask][:, 5:], axis=1)\n",
                "                pred_list.extend(pred_cat)\n",
                "                true_list.extend(true_cat)\n",
                "    return true_list, pred_list\n",
                "\n",
                "y_true, y_pred = extract_predictions(net, loader)\n",
                "\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "disp = ConfusionMatrixDisplay(cm, display_labels=range(10))\n",
                "\n",
                "plt.figure(figsize=(8, 8))\n",
                "disp.plot(cmap='Blues')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.savefig(os.path.join(OUTPUT_PATH, 'confusion_matrix.png'))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "56880a81",
            "metadata": {},
            "source": [
                "## Export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "396bd3e4",
            "metadata": {},
            "outputs": [],
            "source": [
                "PT_FILE = os.path.join(OUTPUT_PATH, \"yolo_fastestv2.pt\")\n",
                "ONNX_FILE = os.path.join(OUTPUT_PATH, \"yolo_fastestv2.onnx\")\n",
                "\n",
                "torch.save(net.state_dict(), PT_FILE)\n",
                "print(f\"Saved: {PT_FILE}\")\n",
                "\n",
                "dummy = torch.randn(1, 1, RESOLUTION, RESOLUTION).to(DEVICE)\n",
                "torch.onnx.export(net, dummy, ONNX_FILE, input_names=[\"input\"], output_names=[\"output\"])\n",
                "print(f\"Exported: {ONNX_FILE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## TFLite Conversion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q onnx==1.16.1 onnx2tf tensorflow onnx-graphsurgeon tf-keras ai-edge-litert sng4onnx simple-onnx-processing-tools\n",
                "\n",
                "import numpy as np\n",
                "print(\"Generating calibration samples...\")\n",
                "cal_iter = iter(loader)\n",
                "cal_samples = [next(cal_iter)[0].numpy() for _ in range(10)]\n",
                "cal_array = np.concatenate(cal_samples, axis=0)\n",
                "np.save(\"calibration.npy\", cal_array)\n",
                "print(f\"Calibration shape: {cal_array.shape}\")\n",
                "\n",
                "TFLITE_DIR = os.path.join(OUTPUT_PATH, \"tflite\")\n",
                "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
                "\n",
                "!onnx2tf -i \"{ONNX_FILE}\" -o \"{TFLITE_DIR}\" -oiqt -qt per-tensor -cind \"input\" \"calibration.npy\" \"[[[[0]]]]\" \"[[[[1]]]]\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from converter import tflite_to_header\n",
                "\n",
                "tflite_file = None\n",
                "for f in os.listdir(TFLITE_DIR):\n",
                "    if f.endswith(\".tflite\"):\n",
                "        tflite_file = os.path.join(TFLITE_DIR, f)\n",
                "        break\n",
                "\n",
                "if tflite_file:\n",
                "    header_file = os.path.join(OUTPUT_PATH, \"model_data.h\")\n",
                "    tflite_to_header(tflite_file, header_file, \"model_data\")\n",
                "    print(f\"Header: {header_file}\")\n",
                "else:\n",
                "    print(\"TFLite file not found!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
