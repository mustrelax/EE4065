{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EE4065 Final Project - Q4 Master Notebook\n",
        "\n",
        "This notebook handles data loading, model training (MobileNet, ResNet, SqueezeNet), and conversion to TFLite Int8 for ESP32.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create directory in Drive\n",
        "TARGET_DIR = '/content/drive/MyDrive/EE4065_Q4'\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "%cd {TARGET_DIR}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "%%writefile mobilenetv1.py\n",
        "# /*---------------------------------------------------------------------------------------------\n",
        "#  * Copyright 2015 The TensorFlow Authors.\n",
        "#  * Copyright (c) 2022-2023 STMicroelectronics.\n",
        "#  * All rights reserved.\n",
        "#  *\n",
        "#  * This software is licensed under terms that can be found in the LICENSE file in\n",
        "#  * the root directory of this software component.\n",
        "#  * If no LICENSE file comes with this software, it is provided AS-IS.\n",
        "#  *--------------------------------------------------------------------------------------------*/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def _depthwise_conv_block(inputs, filters, alpha, depth_multiplier=1, strides=(1, 1), block_id=1):\n",
        "    \"\"\"Adds a depthwise convolution block.\n",
        "\n",
        "    This function defines a depthwise convolution block for use in a mobile\n",
        "    architecture. The block consists of a depthwise convolution, followed by\n",
        "    a pointwise convolution, with batch normalization and ReLU6 activations.\n",
        "\n",
        "    Args:\n",
        "        inputs (tensor): Input tensor.\n",
        "        filters (int): Number of filters for the pointwise convolution.\n",
        "        alpha (float): Width multiplier for the number of filters.\n",
        "        depth_multiplier (int, optional): Depth multiplier for the depthwise convolution.\n",
        "        strides (tuple, optional): Strides for the depthwise convolution.\n",
        "        block_id (int, optional): Block identifier.\n",
        "\n",
        "    Returns:\n",
        "        tensor: Output tensor.\n",
        "\n",
        "    \"\"\"\n",
        "    # Calculate the number of filters for the pointwise convolution.\n",
        "    pointwise_conv_filters = int(filters * alpha)\n",
        "\n",
        "    if strides == (1, 1):\n",
        "        x = inputs\n",
        "    else:\n",
        "        # If the strides are not (1, 1), pad the input tensor to maintain the same output size.\n",
        "        x = layers.ZeroPadding2D(((0, 1), (0, 1)))(inputs)\n",
        "    # Perform the depthwise convolution.\n",
        "    x = layers.DepthwiseConv2D(kernel_size=(3, 3), padding=\"same\" if strides == (1, 1) else \"valid\",\n",
        "                               depth_multiplier=depth_multiplier, strides=strides, use_bias=False,\n",
        "                               name=\"conv_dw_%d\" % block_id, )(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_dw_%d_bn\" % block_id)(x)\n",
        "    x = layers.ReLU(6.0, name=\"conv_dw_%d_relu\" % block_id)(x)\n",
        "\n",
        "    # Perform the pointwise convolution.\n",
        "    x = layers.Conv2D(pointwise_conv_filters, kernel_size=(1, 1), padding=\"same\", use_bias=False, strides=(1, 1),\n",
        "                      name=\"conv_pw_%d\" % block_id)(x)\n",
        "    x = layers.BatchNormalization(name=\"conv_pw_%d_bn\" % block_id)(x)\n",
        "    x = layers.ReLU(6.0, name=\"conv_pw_%d_relu\" % block_id)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def _get_scratch_model(input_shape: tuple = None, alpha: float = None, num_classes: int = None, \n",
        "                      dropout: float = None) -> tf.keras.Model:\n",
        "    \"\"\"Get a MobileNet V1 model from scratch.\n",
        "\n",
        "    This function defines a MobileNet V1 model from scratch using depthwise\n",
        "    convolution blocks.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): Shape of the input tensor.\n",
        "        num_classes (int): Number of output classes.\n",
        "        alpha (float): Width multiplier for the number of filters.\n",
        "        dropout (float, optional): Dropout rate.\n",
        "\n",
        "    Returns:\n",
        "        model: MobileNet V1 model.\n",
        "\n",
        "    \"\"\"\n",
        "    # Define the input tensor.\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # First convolution block.\n",
        "    first_block_filters = int(32 * alpha)\n",
        "    x = layers.Conv2D(first_block_filters, kernel_size=3, strides=(2, 2), padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU(6.)(x)\n",
        "\n",
        "    # Depthwise convolution blocks.\n",
        "    x = _depthwise_conv_block(x, filters=64, alpha=alpha, strides=(1, 1), block_id=1)\n",
        "\n",
        "    x = _depthwise_conv_block(x, filters=128, alpha=alpha, strides=(2, 2), block_id=2)\n",
        "    x = _depthwise_conv_block(x, filters=128, alpha=alpha, strides=(1, 1), block_id=3)\n",
        "\n",
        "    x = _depthwise_conv_block(x, filters=256, alpha=alpha, strides=(2, 2), block_id=4)\n",
        "    x = _depthwise_conv_block(x, filters=256, alpha=alpha, strides=(1, 1), block_id=5)\n",
        "\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(2, 2), block_id=6)\n",
        "\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(1, 1), block_id=7)\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(1, 1), block_id=8)\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(1, 1), block_id=9)\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(1, 1), block_id=10)\n",
        "    x = _depthwise_conv_block(x, filters=512, alpha=alpha, strides=(1, 1), block_id=11)\n",
        "\n",
        "    x = _depthwise_conv_block(x, filters=1024, alpha=alpha, strides=(2, 2), block_id=12)\n",
        "    x = _depthwise_conv_block(x, filters=1024, alpha=alpha, strides=(1, 1), block_id=13)\n",
        "\n",
        "    # Global average pooling and output layer.\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if dropout:\n",
        "        x = keras.layers.Dropout(dropout)(x)\n",
        "    if num_classes > 2:\n",
        "        outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    else:\n",
        "        outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"mobilenet_v1_alpha_{}\".format(alpha))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def _get_transfer_learning_model(input_shape: Tuple[int, int, int] = None, alpha: float = None,\n",
        "                                num_classes: int = None, dropout: float = None,\n",
        "                                weights: str = None) -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Creates a transfer learning model using the MobileNet architecture.\n",
        "\n",
        "    Args:\n",
        "        input_shape: A tuple representing the input shape of the model.\n",
        "        dropout: A float representing the dropout rate of the model.\n",
        "        alpha: A float representing the width multiplier of the MobileNet architecture.\n",
        "        num_classes (int): Number of output classes. Default is None.\n",
        "        weights (str, optional): The pre-trained weights to use. Either \"imagenet\" or None. Defaults to None.\n",
        "    Returns:\n",
        "        A Keras model object with the MobileNet architecture as the backbone and a randomly initialized head.\n",
        "    \"\"\"\n",
        "    # Create a randomly initialized model\n",
        "    random_model = _get_scratch_model(input_shape=input_shape, num_classes=num_classes, alpha=alpha, dropout=dropout)\n",
        "\n",
        "    # Check if input shape is valid for MobileNet architecture\n",
        "    if input_shape[0] in [224, 192, 160, 128]:\n",
        "        input_shape = (input_shape[0], input_shape[1], input_shape[2])\n",
        "        # Use MobileNet architecture with specified input shape\n",
        "        backbone = tf.keras.applications.MobileNet(input_shape, input_tensor=random_model.inputs[0],\n",
        "                                                   alpha=alpha, weights=weights, include_top=False)\n",
        "    else:\n",
        "        # Use default MobileNet architecture\n",
        "        backbone = tf.keras.applications.MobileNet(input_tensor=random_model.inputs[0],\n",
        "                                                   alpha=alpha, weights=weights, include_top=False)\n",
        "\n",
        "    # Copy weights from MobileNet backbone to randomly initialized model\n",
        "    for i, layer in enumerate(backbone.layers):\n",
        "        random_model.layers[i].set_weights(layer.get_weights())\n",
        "\n",
        "    # Return the transfer learning model\n",
        "    return random_model\n",
        "\n",
        "\n",
        "def get_mobilenetv1(input_shape: tuple, alpha: float = None, \n",
        "                     num_classes: int = None, dropout: float = None,\n",
        "                     pretrained_weights: str = \"imagenet\") -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Returns a MobileNetV1 model with a custom classifier.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input tensor.\n",
        "        alpha (float, optional): The width multiplier for the MobileNetV1 backbone. Defaults to None.\n",
        "        dropout (float, optional): The dropout rate for the MobileNetV1 backbone. Defaults to None.\n",
        "        num_classes (int, optional): The number of output classes. Defaults to None.\n",
        "        weights (str, optional): The pre-trained weights to use. Either \"imagenet\" or None.\n",
        "                                 Defaults to \"imagenet\".\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The MobileNetV1 model with a custom classifier.\n",
        "    \"\"\"\n",
        "    \n",
        "    if pretrained_weights:\n",
        "        model = _get_transfer_learning_model(input_shape=input_shape, alpha=alpha,\n",
        "                                            num_classes=num_classes, dropout=dropout,\n",
        "                                            weights=pretrained_weights)\n",
        "    else:\n",
        "        model = _get_scratch_model(input_shape=input_shape, alpha=alpha,\n",
        "                                  num_classes=num_classes, dropout=dropout)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "%%writefile resnetv1.py\n",
        "# /*---------------------------------------------------------------------------------------------\n",
        "#  * Copyright (c) 2022 STMicroelectronics.\n",
        "#  * All rights reserved.\n",
        "#  * This software is licensed under terms that can be found in the LICENSE file in\n",
        "#  * the root directory of this software component.\n",
        "#  * If no LICENSE file comes with this software, it is provided AS-IS.\n",
        "#  *--------------------------------------------------------------------------------------------*/\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def _resnet_layer(inputs: layers.Input, num_filters: int = 16, kernel_size: int = 3, strides: int = 1,\n",
        "                 activation: str = 'relu', batch_normalization: bool = True,\n",
        "                 conv_first: bool = True) -> layers.Activation:\n",
        "    \"\"\"\n",
        "    2D Convolution-Batch Normalization-Activation stack builder for ResNet models.\n",
        "\n",
        "    Args:\n",
        "        inputs: Input tensor from input image or previous layer.\n",
        "        num_filters: Conv2D number of filters.\n",
        "        kernel_size: Conv2D square kernel dimensions.\n",
        "        strides: Conv2D square stride dimensions.\n",
        "        activation: Activation name.\n",
        "        batch_normalization: Whether to include batch normalization.\n",
        "        conv_first: Conv-BN-Activation (True) or BN-Activation-Conv (False).\n",
        "\n",
        "    Returns:\n",
        "        A tensor as input to the next layer.\n",
        "    \"\"\"\n",
        "    conv = layers.Conv2D(num_filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         strides=strides,\n",
        "                         padding='same',\n",
        "                         kernel_initializer='he_normal',\n",
        "                         kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_resnetv1(num_classes: int = None, input_shape: Tuple[int, int, int] = None,\n",
        "                 depth: int = None, dropout: float = None) -> keras.Model:\n",
        "    \"\"\"\n",
        "    ResNet Version 1 Model builder.\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU. Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (down-sampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is doubled.\n",
        "    Within each stage, the layers have the same number filters and the same number of filters.\n",
        "\n",
        "    Args:\n",
        "        num_classes: Number of classes in the dataset.\n",
        "        input_shape: Shape of the input tensor.\n",
        "        depth: Depth of the ResNet model.\n",
        "        dropout: Dropout rate to be applied to the fully connected layer.\n",
        "\n",
        "    Returns:\n",
        "        A Keras model instance.\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError(\"Depth should be 6n+2.\")\n",
        "\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = _resnet_layer(inputs=inputs)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # down sample\n",
        "            y = _resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = _resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match changed dims\n",
        "                x = _resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = layers.add([x, y])\n",
        "            x = layers.Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = layers.AveragePooling2D(pool_size=8)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    if dropout:\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    if num_classes > 2:\n",
        "        outputs = keras.layers.Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal')(x)\n",
        "    else:\n",
        "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=f\"resnet_v1_depth_{depth}\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "%%writefile squeezenetv11.py\n",
        "# /*---------------------------------------------------------------------------------------------\n",
        "#  * Copyright (c) 2016 Refikcanmalli\n",
        "#  * Copyright (c) 2022 STMicroelectronics.\n",
        "#  * All rights reserved.\n",
        "#  * This software is licensed under terms that can be found in the LICENSE file in\n",
        "#  * the root directory of this software component.\n",
        "#  * If no LICENSE file comes with this software, it is provided AS-IS.\n",
        "#  *--------------------------------------------------------------------------------------------*/\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "from keras import layers\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def _fire_module(x: keras.layers.Layer, fire_id: int, squeeze: int = 16, expand: int = 64) -> keras.layers.Layer:\n",
        "    \"\"\"\n",
        "    Fire module for the SqueezeNet model.\n",
        "    Implements expand layer, which has a mix of 1x1 and 3x3 filters,\n",
        "    by using two conv layers concatenated in the channel dimension.\n",
        "    \"\"\"\n",
        "    # Define some constants\n",
        "    sq1x1 = \"squeeze1x1\"\n",
        "    exp1x1 = \"expand1x1\"\n",
        "    exp3x3 = \"expand3x3\"\n",
        "    relu = \"relu_\"\n",
        "    bn = \"bn_\"\n",
        "\n",
        "    s_id = 'fire' + str(fire_id) + '_'\n",
        "\n",
        "    # Get the channel axis\n",
        "    if keras.backend.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "\n",
        "    # Squeeze layer\n",
        "    x = layers.Conv2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=s_id + bn + sq1x1)(x)\n",
        "    x = layers.Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "    # Expand layer\n",
        "    left = layers.Conv2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "    left = layers.BatchNormalization(axis=channel_axis, name=s_id + bn + exp1x1)(left)\n",
        "    left = layers.Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "    right = layers.Conv2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
        "    right = layers.BatchNormalization(axis=channel_axis, name=s_id + bn + exp3x3)(right)\n",
        "    right = layers.Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "    x = layers.concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_squeezenetv11(num_classes: int = None, input_shape: Tuple[int, int, int] = None,\n",
        "                      dropout: float = None) -> keras.Model:\n",
        "    \"\"\"\n",
        "    Returns a SqueezeNet model with the specified number of output classes.\n",
        "    \"\"\"\n",
        "    # Define the input tensor\n",
        "    input_image = layers.Input(input_shape)\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(input_image)\n",
        "    x = layers.BatchNormalization(name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu', name='relu_conv1')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Fire modules\n",
        "    x = _fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = _fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "    x = _fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = _fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "    x = _fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = _fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = _fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = _fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "\n",
        "    # Dropout layer\n",
        "    if dropout:\n",
        "        x = layers.Dropout(dropout, name='drop9')(x)\n",
        "\n",
        "    # Final convolutional layer\n",
        "    x = layers.Conv2D(num_classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "    \n",
        "    # Global average pooling layer\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Softmax activation layer\n",
        "    output = layers.Activation('softmax', name='loss')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = keras.Model(input_image, output, name='SqueezeNet_v1.1')\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "%%writefile train_models.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from mobilenetv1 import get_mobilenetv1\n",
        "from resnetv1 import get_resnetv1\n",
        "from squeezenetv11 import get_squeezenetv11\n",
        "\n",
        "# Configuration\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "NUM_CLASSES = 10\n",
        "MODELS_DIR = \"models\"\n",
        "PLOTS_DIR = \"plots\"\n",
        "\n",
        "def load_data():\n",
        "    print(\"Loading MNIST dataset...\")\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    x_train = x_train.astype(\"float32\") / 255.0\n",
        "    x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "    # Add channel dimension\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "    x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "def create_datasets(x_train, y_train, x_test, y_test):\n",
        "    def preprocess(image, label):\n",
        "        # Resize to 64x64\n",
        "        image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "        return image, label\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_ds = train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train_ds = train_ds.shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    test_ds = test_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return train_ds, test_ds\n",
        "\n",
        "def save_plots(history, y_true, y_pred_classes, model_name):\n",
        "    if not os.path.exists(PLOTS_DIR):\n",
        "        os.makedirs(PLOTS_DIR)\n",
        "\n",
        "    # 1. Accuracy & Loss\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PLOTS_DIR, f\"{model_name}_metrics.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(os.path.join(PLOTS_DIR, f\"{model_name}_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Print Classification Report\n",
        "    print(f\"\\n--- Classification Report for {model_name} ---\")\n",
        "    print(classification_report(y_true, y_pred_classes, digits=4))\n",
        "\n",
        "def train_and_evaluate(model, train_ds, test_ds, y_test, model_name, input_shape):\n",
        "    print(f\"\\n========================================\")\n",
        "    print(f\"Training {model_name}...\")\n",
        "    print(f\"========================================\")\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(train_ds, epochs=EPOCHS, validation_data=test_ds)\n",
        "    \n",
        "    # Save Model\n",
        "    model.save(os.path.join(MODELS_DIR, f\"{model_name}.keras\"))\n",
        "    print(f\"{model_name} saved.\")\n",
        "\n",
        "    # Evaluate on Test Set\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(test_ds)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Generate Plots\n",
        "    save_plots(history, y_test, y_pred_classes, model_name)\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(MODELS_DIR):\n",
        "        os.makedirs(MODELS_DIR)\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = load_data()\n",
        "    train_ds, test_ds = create_datasets(x_train, y_train, x_test, y_test)\n",
        "    input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "    # 1. MobileNet\n",
        "    mobilenet = get_mobilenetv1(input_shape=input_shape, alpha=0.25, num_classes=NUM_CLASSES, pretrained_weights=None)\n",
        "    train_and_evaluate(mobilenet, train_ds, test_ds, y_test, \"mobilenetv1\", input_shape)\n",
        "\n",
        "    # 2. ResNet\n",
        "    # ResNet20\n",
        "    resnet = get_resnetv1(input_shape=input_shape, depth=20, num_classes=NUM_CLASSES)\n",
        "    train_and_evaluate(resnet, train_ds, test_ds, y_test, \"resnetv1\", input_shape)\n",
        "\n",
        "    # 3. SqueezeNet\n",
        "    squeezenet = get_squeezenetv11(input_shape=input_shape, num_classes=NUM_CLASSES)\n",
        "    train_and_evaluate(squeezenet, train_ds, test_ds, y_test, \"squeezenetv11\", input_shape)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "%%writefile convert_models.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "IMG_SIZE = 64\n",
        "MODELS_DIR = \"models\"\n",
        "HEADERS_DIR = \"headers\"\n",
        "\n",
        "def load_data_for_calibration():\n",
        "    print(\"Loading MNIST dataset for calibration...\")\n",
        "    (x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "    \n",
        "    # Just take a subset for calibration\n",
        "    x_train = x_train[:1000]\n",
        "    \n",
        "    # Normalize to [0, 1]\n",
        "    x_train = x_train.astype(\"float32\") / 255.0\n",
        "    \n",
        "    # Add channel dimension\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "    resized_images = []\n",
        "    for img in x_train:\n",
        "        # tf.image.resize expects 3D or 4D tensor\n",
        "        img_tensor = tf.convert_to_tensor(img)\n",
        "        img_resized = tf.image.resize(img_tensor, [IMG_SIZE, IMG_SIZE])\n",
        "        resized_images.append(img_resized.numpy())\n",
        "    \n",
        "    return np.array(resized_images)\n",
        "\n",
        "def convert_to_tflite_int8(model_path, calibration_data):\n",
        "    print(f\"Converting {model_path} to TFLite Int8...\")\n",
        "    \n",
        "    # Load Keras model\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model {model_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Create converter\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    \n",
        "    # Int8 Quantization settings\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    \n",
        "    def rep_dataset():\n",
        "        for i in range(len(calibration_data)):\n",
        "            # Yield: [1, 64, 64, 1]\n",
        "            yield [np.expand_dims(calibration_data[i], axis=0)]\n",
        "            \n",
        "    converter.representative_dataset = rep_dataset\n",
        "    \n",
        "    # Ensure full integer quantization\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "    \n",
        "    tflite_model = converter.convert()\n",
        "    return tflite_model\n",
        "\n",
        "def convert_to_c_array(tflite_model, model_name):\n",
        "    # Hex dump\n",
        "    hex_array = []\n",
        "    for byte in tflite_model:\n",
        "        hex_array.append(f\"0x{byte:02x}\")\n",
        "    \n",
        "    # Format C code\n",
        "    c_code = f\"// Auto-generated C header for {model_name}\\n\"\n",
        "    c_code += f\"#ifndef {model_name.upper()}_MODEL_H\\n\"\n",
        "    c_code += f\"#define {model_name.upper()}_MODEL_H\\n\\n\"\n",
        "    c_code += f\"const unsigned char {model_name}_model[] = {{\\n\"\n",
        "    \n",
        "    # Group by 12 bytes per line for readability\n",
        "    for i in range(0, len(hex_array), 12):\n",
        "        line = \", \".join(hex_array[i:i+12])\n",
        "        c_code += f\"  {line},\\n\"\n",
        "        \n",
        "    c_code += \"};\\n\\n\"\n",
        "    c_code += f\"const unsigned int {model_name}_model_len = {len(tflite_model)};\\n\\n\"\n",
        "    c_code += \"#endif\\n\"\n",
        "    \n",
        "    return c_code\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(HEADERS_DIR):\n",
        "        os.makedirs(HEADERS_DIR)\n",
        "        \n",
        "    calibration_data = load_data_for_calibration()\n",
        "    \n",
        "    model_files = [\n",
        "        \"mobilenetv1.keras\",\n",
        "        \"resnetv1.keras\",\n",
        "        \"squeezenetv11.keras\"\n",
        "    ]\n",
        "    \n",
        "    for filename in model_files:\n",
        "        model_name = filename.split('.')[0]\n",
        "        model_path = os.path.join(MODELS_DIR, filename)\n",
        "        \n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"Model file not found: {model_path}. Skipping.\")\n",
        "            continue\n",
        "            \n",
        "        tflite_model = convert_to_tflite_int8(model_path, calibration_data)\n",
        "        \n",
        "        if tflite_model:\n",
        "            # Save .tflite file\n",
        "            tflite_path = os.path.join(HEADERS_DIR, f\"{model_name}.tflite\")\n",
        "            with open(tflite_path, \"wb\") as f:\n",
        "                f.write(tflite_model)\n",
        "            print(f\"Saved {tflite_path}\")\n",
        "                \n",
        "            header_name = model_name.replace(\"v1\", \"\").replace(\"v11\", \"\") + \"_model\" \n",
        "            \n",
        "            c_code = convert_to_c_array(tflite_model, header_name)\n",
        "            \n",
        "            header_path = os.path.join(HEADERS_DIR, f\"{header_name}.h\")\n",
        "            with open(header_path, \"w\") as f:\n",
        "                f.write(c_code)\n",
        "            print(f\"Saved {header_path}\")\n",
        "            \n",
        "            # Verify first few lines\n",
        "            if \"mobilenet\" in header_name:\n",
        "                print(f\"\\n--- Verification: First 5 lines of {header_path} ---\")\n",
        "                print(\"\\n\".join(c_code.splitlines()[:5]))\n",
        "                print(\"----------------------------------------------------\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "!python train_models.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "!python convert_models.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "!ls -l headers/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "!head -n 20 headers/mobilenet_model.h\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
